---
sidebar_position: 1
---

# API Reference: Lexers Module (`lexers`)

Central to SpiceCode's ability to understand source code across different languages is the `lexers` module. This package contains the fundamental components responsible for the first phase of code analysis: lexical analysis, or tokenization. Unlike tools that rely on external libraries or language-specific compilers, SpiceCode employs its own set of native lexers, meticulously crafted for each supported language. This approach ensures independence, consistency, and fine-grained control over how source code is interpreted at the most basic level, much like a Fremen relies on their own senses and knowledge rather than off-world instruments.

## Purpose of Lexical Analysis

Lexical analysis is the process of reading the sequence of characters that make up the source code and converting them into a sequence of meaningful symbols called tokens. These tokens represent the building blocks of the language, such as keywords (`def`, `class`, `func`), identifiers (variable names, function names), operators (`+`, `=`, `==`), literals (numbers, strings), punctuation (parentheses, commas), and comments. This stream of tokens is then passed to the parser for the next stage of analysis (syntactic analysis).

## Structure of the `lexers` Module

The `lexers` module is organized to support multiple languages in a modular fashion:

```
lexers/
├── __init__.py
├── token.py          # Defines the base Token class
├── golang/
│   ├── __init__.py
│   └── golexer.py      # Lexer implementation for Go
├── javascript/
│   ├── __init__.py
│   └── javascriptlexer.py # Lexer implementation for JavaScript
├── python/
│   ├── __init__.py
│   └── pythonlexer.py  # Lexer implementation for Python
└── ruby/
    ├── __init__.py
    └── rubylexer.py    # Lexer implementation for Ruby
```

### `token.py`

This file defines the fundamental `Token` class (or a similar structure). Each token generated by a lexer is typically an instance of this class (or a named tuple/dataclass), containing information such as:

*   **Type:** The category of the token (e.g., KEYWORD, IDENTIFIER, OPERATOR, STRING_LITERAL, COMMENT, WHITESPACE, EOF - End Of File).
*   **Value:** The actual text sequence from the source code that constitutes the token (e.g., `"def"`, `"myVariable"`, `"+"`, `"# This is a comment"`).
*   **Line Number:** The line in the source file where the token begins.
*   **Column Number:** The column position on the line where the token begins.

This structured token information is essential for the parser and subsequent analyzers.

### Language-Specific Lexer Modules (`golang`, `javascript`, `python`, `ruby`)

Each subdirectory within `lexers` corresponds to a supported programming language and contains the specific lexer implementation for that language.

*   **`golexer.py` (in `golang/`):** Implements the lexical analysis logic specific to the Go language syntax, handling its keywords, operators, comments (`//`, `/* */`), string literals, numeric literals, etc.
*   **`javascriptlexer.py` (in `javascript/`):** Implements the lexer for JavaScript, recognizing its keywords, operators, comments (`//`, `/* */`), various literal types (including template literals and regex literals), and syntax features.
*   **`pythonlexer.py` (in `python/`):** Implements the lexer for Python, paying close attention to its keywords, operators, comments (`#`), string formats (f-strings, raw strings), numeric literals, and crucially, handling indentation and dedentation as significant tokens.
*   **`rubylexer.py` (in `ruby/`):** Implements the lexer for Ruby, identifying its keywords (including block terminators like `end`), operators, comments (`#`), symbols, string literals, heredocs, and other syntactic elements.

Each language-specific lexer class typically inherits from a base lexer class or follows a common interface, taking the source code string as input and providing an iterator or method to yield tokens one by one until the end of the file is reached.

## Usage within SpiceCode

The appropriate lexer is selected dynamically based on the detected language of the input file (usually determined by the file extension via the `utils.get_lang` and `utils.get_lexer` utilities). The chosen lexer processes the source code, and the resulting stream of tokens is fed into the `parser` module to build a structured representation (like an AST) for further analysis by the modules in `spice/analyzers`.

Understanding the role and structure of the `lexers` module is key for contributors looking to extend SpiceCode's language support or refine the analysis for existing languages. It represents the critical first step in SpiceCode's journey from raw source code to actionable insights.
